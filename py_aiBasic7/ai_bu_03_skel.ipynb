{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ai_bu_04.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfobKjJRIKMC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99ddb865-e135-4e41-c537-a657e06e6d63"
      },
      "source": [
        "import torch\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import time\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# for reproducibility\n",
        "random.seed(777)\n",
        "torch.manual_seed(777)\n",
        "if device == 'cuda':\n",
        "    torch.cuda.manual_seed_all(777)\n",
        "\n",
        "# parameters\n",
        "training_epochs = 20\n",
        "batch_size = 256\n",
        "\n",
        "# MNIST dataset\n",
        "mnist_train = dsets.MNIST(root='MNIST_data/',\n",
        "                          train=True,\n",
        "                          transform=transforms.ToTensor(),\n",
        "                          download=True)\n",
        "\n",
        "mnist_test = dsets.MNIST(root='MNIST_data/',\n",
        "                         train=False,\n",
        "                         transform=transforms.ToTensor(),\n",
        "                         download=True)\n",
        "\n",
        "# dataset loader\n",
        "data_loader = torch.utils.data.DataLoader(dataset=mnist_train,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=True,\n",
        "                                          drop_last=True)\n",
        "\n",
        "# MNIST data image of shape 28 * 28 = 784\n",
        "linear = torch.nn.Linear(784, 10, bias=True).to(device)\n",
        "\n",
        "# define cost/loss & optimizer\n",
        "criterion = torch.nn.CrossEntropyLoss().to(device)    # Softmax is internally computed.\n",
        "optimizer = torch.optim.SGD(linear.parameters(), lr=0.1)\n",
        "\n",
        "start = time.time()  # start time\n",
        "for epoch in range(training_epochs):\n",
        "    avg_cost = 0\n",
        "    total_batch = len(data_loader)\n",
        "\n",
        "    for X, Y in data_loader:\n",
        "        # reshape input image into [batch_size by 784]\n",
        "        # label is not one-hot encoded\n",
        "        X = X.view(-1, 28 * 28).to(device)\n",
        "        Y = Y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        hypothesis = linear(X)\n",
        "        cost = criterion(hypothesis, Y)\n",
        "        cost.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        avg_cost += cost / total_batch\n",
        "\n",
        "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
        "\n",
        "print('Learning finished')\n",
        "print(\"time :\", '''???''' )  # Q1) Complete the code to print the total execution time."
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0001 cost = 0.712997079\n",
            "Epoch: 0002 cost = 0.430425495\n",
            "Epoch: 0003 cost = 0.384661943\n",
            "Epoch: 0004 cost = 0.361041397\n",
            "Epoch: 0005 cost = 0.346561611\n",
            "Epoch: 0006 cost = 0.335881978\n",
            "Epoch: 0007 cost = 0.328014225\n",
            "Epoch: 0008 cost = 0.321718752\n",
            "Epoch: 0009 cost = 0.316227525\n",
            "Epoch: 0010 cost = 0.312065393\n",
            "Epoch: 0011 cost = 0.308147997\n",
            "Epoch: 0012 cost = 0.304742455\n",
            "Epoch: 0013 cost = 0.302093059\n",
            "Epoch: 0014 cost = 0.299490869\n",
            "Epoch: 0015 cost = 0.296950549\n",
            "Epoch: 0016 cost = 0.295024067\n",
            "Epoch: 0017 cost = 0.292878270\n",
            "Epoch: 0018 cost = 0.291426718\n",
            "Epoch: 0019 cost = 0.289959490\n",
            "Epoch: 0020 cost = 0.288146228\n",
            "Learning finished\n",
            "time : 101.39820718765259\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtnIw1LOMTAQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "outputId": "21e67a96-c529-41d0-8443-e7eec7066d02"
      },
      "source": [
        "# Test the model using test sets\n",
        "with torch.no_grad():\n",
        "    X_test = mnist_test.test_data.view(-1, 28 * 28).float().to(device)\n",
        "    Y_test = mnist_test.test_labels.to(device)\n",
        "\n",
        "    prediction = linear(X_test)\n",
        "    correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
        "    accuracy = correct_prediction.float().mean()\n",
        "    print('Accuracy:', accuracy.item())\n",
        "\n",
        "    # Q2) Complete the following code so that read and print one test data of the last 4 digits of your student ID.\n",
        "    # ex. In case of s_id = 2008710991, read and print 0992th test data sample.\n",
        "    r = '''???''' \n",
        "    X_single_data = mnist_test.test_data[r:r + 1].view(-1, 28 * 28).float().to(device)\n",
        "    Y_single_data = mnist_test.test_labels[r:r + 1].to(device)\n",
        "\n",
        "    print('Label: ', Y_single_data.item())\n",
        "    single_prediction = linear(X_single_data)\n",
        "    print('Prediction: ', torch.argmax(single_prediction, 1).item())\n",
        "\n",
        "    plt.imshow(mnist_test.test_data[r:r + 1].view(28, 28), cmap='Greys', interpolation='nearest')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8953999876976013\n",
            "Label:  5\n",
            "Prediction:  3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:67: UserWarning: test_data has been renamed data\n",
            "  warnings.warn(\"test_data has been renamed data\")\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:57: UserWarning: test_labels has been renamed targets\n",
            "  warnings.warn(\"test_labels has been renamed targets\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBhihZDe-Taj",
        "outputId": "5c056c5c-8698-45ae-b695-a6724d879e28"
      },
      "source": [
        "import torch\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.init\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# for reproducibility\n",
        "torch.manual_seed(0)\n",
        "if device == 'cuda':\n",
        "    torch.cuda.manual_seed_all(0)\n",
        "\n",
        "# parameters\n",
        "learning_rate = 0.001\n",
        "training_epochs = 15\n",
        "batch_size = 100\n",
        "\n",
        "# MNIST dataset\n",
        "mnist_train = dsets.MNIST(root='MNIST_data/',\n",
        "                          train=True,\n",
        "                          transform=transforms.ToTensor(),\n",
        "                          download=True)\n",
        "\n",
        "mnist_test = dsets.MNIST(root='MNIST_data/',\n",
        "                         train=False,\n",
        "                         transform=transforms.ToTensor(),\n",
        "                         download=True)\n",
        "\n",
        "\n",
        "# dataset loader\n",
        "data_loader = torch.utils.data.DataLoader(dataset=mnist_train,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=True,\n",
        "                                          drop_last=True)\n",
        "\n",
        "# CNN Model (2 conv layers)\n",
        "class CNN(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        # L1 ImgIn shape=(?, 28, 28, 1)\n",
        "        #    Conv     -> (?, 28, 28, 32)\n",
        "        #    Pool     -> (?, 14, 14, 32)\n",
        "        self.layer1 = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        # L2 ImgIn shape=(?, 14, 14, 32)\n",
        "        #    Conv      ->(?, 14, 14, 64)\n",
        "        #    Pool      ->(?, 7, 7, 64)\n",
        "        self.layer2 = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        # Final FC 7x7x64 inputs -> 10 outputs\n",
        "        self.fc = torch.nn.Linear(7 * 7 * 64, 10, bias=True)\n",
        "        torch.nn.init.xavier_uniform_(self.fc.weight)\n",
        "\n",
        "        self.layer3 = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        # Final FC 7x7x64 inputs -> 10 outputs\n",
        "        self.fc1 = torch.nn.Linear(3 * 3 * 128, 625, bias=True)\n",
        "        self.relu = torch.nn.ReLU()\n",
        "        self.fc2 = torch.nn.Linear(625, 10, bias=True)\n",
        "        torch.nn.init.xavier_uniform_(self.fc1.weight)\n",
        "        torch.nn.init.xavier_uniform_(self.fc2.weight)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "\n",
        "        out = out.view(out.size(0), -1)   # Flatten them for FC\n",
        "        out = self.fc1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.fc2(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "# instantiate CNN model\n",
        "model = CNN().to(device)\n",
        "\n",
        "# define cost/loss & optimizer\n",
        "criterion = torch.nn.CrossEntropyLoss().to(device)    # Softmax is internally computed.\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# train my model\n",
        "total_batch = len(data_loader)\n",
        "print('Learning started. It takes sometime.')\n",
        "for epoch in range(training_epochs):\n",
        "    avg_cost = 0\n",
        "\n",
        "    for X, Y in data_loader:\n",
        "        # image is already size of (28x28), no reshape\n",
        "        # label is not one-hot encoded\n",
        "        X = X.to(device)\n",
        "        Y = Y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        hypothesis = model(X)\n",
        "        cost = criterion(hypothesis, Y)\n",
        "        cost.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        avg_cost += cost / total_batch\n",
        "    print('[Epoch: {:>4}] cost = {:>.9}'.format(epoch + 1, avg_cost))\n",
        "print('Learning Finished!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning started. It takes sometime.\n",
            "[Epoch:    1] cost = 0.159744292\n",
            "[Epoch:    2] cost = 0.0419970155\n",
            "[Epoch:    3] cost = 0.029343972\n",
            "[Epoch:    4] cost = 0.0217829812\n",
            "[Epoch:    5] cost = 0.0175294299\n",
            "[Epoch:    6] cost = 0.0143893845\n",
            "[Epoch:    7] cost = 0.0118126171\n",
            "[Epoch:    8] cost = 0.00933356024\n",
            "[Epoch:    9] cost = 0.010683774\n",
            "[Epoch:   10] cost = 0.00747025246\n",
            "[Epoch:   11] cost = 0.00713157887\n",
            "[Epoch:   12] cost = 0.00728846621\n",
            "[Epoch:   13] cost = 0.00800966471\n",
            "[Epoch:   14] cost = 0.00457668444\n",
            "[Epoch:   15] cost = 0.0066513042\n",
            "Learning Finished!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2QYsweQ-VRf",
        "outputId": "80ba5835-c092-4423-c303-4a6015359348"
      },
      "source": [
        "# Test model and check accuracy\n",
        "with torch.no_grad():\n",
        "    X_test = mnist_test.test_data.view(len(mnist_test), 1, 28, 28).float().to(device)\n",
        "    Y_test = mnist_test.test_labels.to(device)\n",
        "\n",
        "    prediction = model(X_test)\n",
        "    correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
        "    accuracy = correct_prediction.float().mean()\n",
        "    print('Accuracy:', accuracy.item())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9869999885559082\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:69: UserWarning: test_data has been renamed data\n",
            "  warnings.warn(\"test_data has been renamed data\")\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:59: UserWarning: test_labels has been renamed targets\n",
            "  warnings.warn(\"test_labels has been renamed targets\")\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}